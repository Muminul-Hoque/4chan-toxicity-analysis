# ğŸ§  4chan Toxicity Analysis  
**Yang Lab Screening Task â€“ September 2025**

# *[âš ï¸ This README is a work in progress. Final documentation will be updated before submission.]*

![Python](https://img.shields.io/badge/Python-3.9%2B-blue?logo=python)
![Git](https://img.shields.io/badge/Version%20Control-Git-orange?logo=git)
![OpenAI API](https://img.shields.io/badge/API-OpenAI-green?logo=openai)
![Google Perspective API](https://img.shields.io/badge/API-Google%20Perspective-lightgrey?logo=google)
![License](https://img.shields.io/badge/License-MIT-success)
 

This repository contains a complete pipeline for analyzing toxicity patterns on 4chanâ€™s politically incorrect board (/pol/) using two automated content moderation systems: **OpenAIâ€™s Moderation API** and **Googleâ€™s Perspective API**.  

The project demonstrates proficiency in **ethical social media data collection, API integration, statistical analysis, version control, and technical reporting** â€” core competencies for research in the Yang Lab.  

---

## ğŸ“ Repository Structure
```
4chan-toxicity-analysis/
â”œâ”€â”€ 4chan_toxicity_research_report_Muhamed_Muminul_Hoque.pdf
â”œâ”€â”€ README.md
â”œâ”€â”€ LICENSE
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ pol_posts_raw.json
â”‚   â”œâ”€â”€ pol_posts.json
â”‚   â””â”€â”€ pol_posts_with_scores.json
â”‚
â”œâ”€â”€ src/
â”‚   â””â”€â”€ main.py
|   â””â”€â”€ data_collection.py           
|   â””â”€â”€ processing.py                
|   â””â”€â”€ api_integration.py
â”‚   â””â”€â”€ analysis.py        
â”‚
â”œâ”€â”€ results/                          # Visual outputs from analysis
â”‚   â”œâ”€â”€ correlation_heatmap.png
â”‚   â”œâ”€â”€ agreement_matrix.png
â”‚   â”œâ”€â”€ toxicity_distributions.png
â”‚   â”œâ”€â”€ openai_toxicity_distribution.png
â”‚   â”œâ”€â”€ openai_hate_distribution.png
â”‚   â”œâ”€â”€ openai_sexual_distribution.png
â”‚   â”œâ”€â”€ openai_self-harm_distribution.png
â”‚   â”œâ”€â”€ openai_violence_distribution.png
â”‚   â”œâ”€â”€ openai_harassment_distribution.png
â”‚   â”œâ”€â”€ openai_harassment_threatening_distribution.png
â”‚   â”œâ”€â”€ openai_hate_threatening_distribution.png
â”‚   â”œâ”€â”€ openai_self-harm_intent_distribution.png
â”‚   â”œâ”€â”€ openai_sexual_minors_distribution.png
â”‚   â”œâ”€â”€ openai_violence_graphic_distribution.png
â”‚   â”œâ”€â”€ persp_toxicity_distribution.png
â”‚   â”œâ”€â”€ persp_identity_attack_distribution.png
â”‚   â”œâ”€â”€ persp_insult_distribution.png
â”‚   â”œâ”€â”€ persp_threat_distribution.png
â”‚   â”œâ”€â”€ persp_severe_toxicity_distribution.png
â”‚   â”œâ”€â”€ persp_obscene_distribution.png
â”‚   â”œâ”€â”€ persp_profanity_distribution.png
â”‚   â”œâ”€â”€ persp_sexually_explicit_distribution.png
â”‚   â”œâ”€â”€ persp_spam_distribution.png
â”‚   â”œâ”€â”€ persp_flirtation_distribution.png
â”‚
â”œâ”€â”€ tables/
â”‚   â”œâ”€â”€ disagreement_by_op.csv
â”‚   â”œâ”€â”€ disagreement_by_country.csv
â”‚   â”œâ”€â”€ disagreement_by_subject.csv
â”‚   â”œâ”€â”€ disagreement_by_op.md
â”‚   â”œâ”€â”€ disagreement_by_country.md
â”‚   â””â”€â”€ disagreement_by_subject.md
â”‚
â”œâ”€â”€ summary/
â”‚   â””â”€â”€ analysis_summary.json

```
---

## âš™ï¸ Setup Instructions

### 1. Clone the repository
```bash
git clone https://github.com/muminul-hoque/4chan-toxicity-analysis.git
cd 4chan-toxicity-analysis
```
### 2. Create a virtual environment
#### For Linux/macOS:
```bash
python3 -m venv venv
source venv/bin/activate
```
#### For Windows:
```bash
python -m venv venv
venv\Scripts\activate
```
## 3. Install dependencies:
```bash
pip install -r requirements.txt
```
## 4. Configure API keys
Create a .env file in the root directory:
```env
OPENAI_API_KEY=your_openai_api_key
PERSPECTIVE_API_KEY=your_google_perspective_api_key
```
## ğŸ“Š Methodology Overview

### ğŸ”¹ Data Collection
- Scraped 5,000â€“10,000 posts from /pol/ using 4chanâ€™s public JSON API  
- Implemented rate limiting (1 request/sec), duplicate filtering, and metadata extraction  
- Stored structured data in JSON format for reproducibility  

### ğŸ”¹ API Integration
- Queried OpenAI Moderation API and Google Perspective API for each post  
- Extracted toxicity scores and flags across multiple categories  
- Implemented retry logic, error handling, and checkpointing for robustness  

### ğŸ”¹ Comparative Analysis
- Correlation analysis between API scores  
- Agreement/disagreement pattern identification  
- Category-wise toxicity distribution  
- Statistical significance testing  
- Visualizations using `matplotlib` and `seaborn`  

---

## ğŸ” Research Questions
- How well do OpenAI and Perspective APIs agree on toxicity detection?  
- Which content categories show the highest disagreement?  
- Which API is more sensitive to specific toxic behaviors?  
- What patterns emerge in false positive/negative classifications?  

---

## ğŸ¤– Generative AI Usage Statement
This project leveraged **Microsoft Copilot** to assist with:
- Code debugging and optimization  
- README and documentation drafting  
- Statistical analysis planning  
- Report structuring and phrasing  

All AI-generated content was reviewed, validated, and integrated manually. The use of generative AI tools was limited to support tasks and did not replace original analytical work.

---

## ğŸ” Notes on Ethics and Privacy
- All data collected from 4chan was publicly accessible and gathered in accordance with platform guidelines.  
- API keys and sensitive credentials are excluded from the repository.  
- Toxicity analysis was conducted for research purposes only and does not reflect endorsement or judgment of any individual content.

---

## ğŸ“¬ Contact
For questions or collaboration, please reach out via GitHub or email:  
**yang3kc@gmail.com** **muminul951@gmail.com**
